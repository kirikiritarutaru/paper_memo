# Faith and Fate: Limits of Transformers on Compositionality

## 論文について (掲載ジャーナルなど)
- [Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jiang, Bill Yuchen Lin, Peter West, Chandra Bhagavatula, Ronan Le Bras, Jena D. Hwang, Soumya Sanyal, Sean Welleck, Xiang Ren, Allyson Ettinger, Zaid Harchaoui, Yejin Choi](https://arxiv.org/abs/2305.18654)

## 概要
- 近年、LLMは大きな注目を集め、特に複雑な多段階の推論を必要とするタスクで高性能を発揮することがよく知られている
- しかしながら、驚くほど些細な問題で失敗する場合もある
  - 「なぜ失敗するのか」について検討した
- 本論文は、以下の4つのコントリビューションがある
    - LLMを解明する試みとして、3つの代表的な compositional tasks においてモデルの限界を調査
        - 桁の多い数字の掛け算、ロジックグリッドパズル、古典的な動的計画問題
        - compositional tasks =「問題をサブステップに分解し、それらのステップの結果を合成して正解を導く」ような問題
    - 複雑さのレベルを体系的に定量化するため、compositional tasksを計算グラフとして定式化
    - Transformers の compositional tasksを解く方法の洞察
      - 体系的な問題解決スキルを獲得しているわけではない
      - 多段階の構成的推論を線形化された部分グラフのマッチングに還元することで、compositional tasksを解いている（ようだ）
    - タスクの複雑性が増加するにしたがい、Transformersのパフォーマンスが急速に低下する実験結果

## 問題設定と解決したこと
- 問題設定
  - LLM の compositional tasks を解く能力の限界を知りたい
    - LLMは、いろんなタスクで高性能を発揮する一方、簡単な $3\times3$ の計算の正解率は55%~59% ←なんで？？
- 仮説
    1. Transformers は多段階の構成的推論を線形化されたパスマッチングに還元することにより、compositional tasksを解く
       - パターンマッチングによるショートカット学習は、トレーニング中に類似の構成パターンが利用可能な場合、高速な正解を得ることができる
       - 一般的でない例や複雑な例に対するロバストな汎化はできない
    2. エラーの伝播により、Transformers は新しいパターンの高複雑度の compositional tasks を解くことは本質的な限界がある
       - 計算プロセスの初期段階でのエラーが後続のステップにおける複合エラーにつながり、モデルが正解を見つけることを妨げるだろう

- 解決したこと
  - compositional tasks の複雑さのレベルを体系的に定量化する方法を提案
  - LLMの推論力を調べた
    - LLMの推論力の傾向
      - タスクに特化したデータを用いた学習は、ドメイン内のインスタンスや低い構成複雑度のもとではほぼ完璧な性能を示す
      - この領域外のインスタンスでは大きく失敗する
    - LLMのドメインの領域内外でのギャップにより以下のことが示唆される
      - **人間のような推論ステップを促したり訓練したとしても、入出力のシーケンスを尤もらしく繋げる方法（maximum likelihood training）からは、体系的な問題解決能力が生まれないのではないか**
  - LLMの失敗するケースの分析の結果
    - **モデルは単一ステップの演算を記憶することはできるが、それらを正しい推論パスに構成することはできず、深い全体的な課題理解ではなく、浅い暗記学習に基づいて予測を行うことがほとんど！**

## 何をどう使ったのか
- 人間の問題解決能力はグラフ構造として概念化することができる
  - 各頂点は部分解を表し、辺はこれらの解を修正するために適用できる演算子を表す
  - 以下の図1にしめすように、計算グラフと対応する評価方法を使用して、Transformers の推論力を評価する
    - <img src="picture/Faith and Fate; Limits of Transformers on Compositionality Figure 1.png" alt="Faith and Fate; Limits of Transformers on Compositionality Figure 1" style="zoom: 33%;" />
- 推論を計算グラフのとして表現することで、タスクの複雑さを様々な視点で測定することができる
  - 推論の深さ (reasoning depth)
    - タスクを解決するために必要なマルチホップ推論の最大値の（代わりに示す）指標
  - 推論の幅 (reasoning width)
    - 計算中に並列して維持する変数の最大値の指標
  - グラフの平均並列度 (average parallelism)
    - 「推論の深さ」と「推論の幅」の比
    - グラフを通して計算の平均幅（保持すべき変数の数の平均）を算出する指標
  - 相対情報利得
    - 計算グラフの任意のノードの、「そのノードより前のノードの集合」に対する影響力を分析できる指標
    - この指標をいれるモチベーション
      - モデルの性能を評価するとき、全体的に不正解でも部分的に正解であるケースがある
      - 部分的な成功におけるモデルの戦略を理解したいので、モデルが認識しやすい表層パターンを予測したい
        - [意見] モデルが認識しやすい表層パターン？？？？？
- モデルに解かせる compositional tasks の定義
  1. 乗算 (Multiplication)
     - 桁の多い数同士の乗算は、手続き的ルールに基づいて数値記号の演算を実行する必要がある
     - 計算グラフを構築する際に、long-form multiplication アルゴリズムを用いる
  2. アインシュタインのパズル (Einstein's Puzzle)
     - 制約充足問題を解くベンチマークとして使われる有名な論理パズル
     - 異なる形の家があり、それぞれの家に住む人の出身国・好みの飲み物・好みのタバコ・飼っているペットなどの説明文が箇条書きでたくさん並んでる。たくさんの説明文を頼りに、それぞれの家に住んでいる家族とその好みを当てるパズル
  3. 動的計画法問題
     - 複雑な問題をより単純な部分問題に再帰的に分解して解く動的計画法を使う問題
       - 整数の並びが与えられたとき、その並びの中の２つの数が元の並びの中で隣接しないような最大の和を持つ並びを見つける（みたいな）

## 主張の有効性の検証方法
- 実験設定
  - モデル：GPT3, ChatGPT, GPT4
  - 評価時の学習：ゼロショット、few ショット、ファインシューニング
  - モデルの回答形式：質問-答え形式、質問-スクラッチパッド（←計算グラフを言語化したもの）形式

- ゼロショット時の結果
  - 問題の複雑さが増すにつれ、ほぼ完璧に回答→ほぼ不正解へと大幅に悪化する
    - <img src="picture/Faith and Fate; Limits of Transformers on Compositionality Figure 2.png" alt="Faith and Fate; Limits of Transformers on Compositionality Figure 2" style="zoom: 33%;" />
      - 問題の複雑さは、問題サイズ or 平均並列度で測った
  - ゼロショット時の結果からわかること
    - **compositional tasksを解くための基本的な操作の組み合わせ方をモデルに教えるには、事前学習では不十分**

- 質問-回答形式の学習による Transformers の限界

  - 疑問：

    - ゼロショットの結果が悪い。なぜか？
      - モデルの性能に限界があるのは、事前学習時にタスクに特化したデータがなかったかもしれない

  - 解決案：

    - ファインチューニングしてみよう

      - 乗算、アインシュタインのパズル、動的計画問題の小さい問題（最大問題サイズ3）とその回答をいれまくってGPT-3をチューニング

  - 結果：

    - 見たことある範囲の複雑さの問題は解けるようになったが、領域外の問題では性能が急激に低下

    - <img src="picture/Faith and Fate; Limits of Transformers on Compositionality Figure 4.png" alt="Faith and Fate; Limits of Transformers on Compositionality Figure 4" style="zoom: 33%;" />

  - 結論：

    - **系統的な問題解決能力は、タスク固有のデータに対する徹底的な訓練によって出現するものではない**ことが示唆された

- 質問-スクラッチパッド形式の学習による Transformers の限界

  - 疑問：
    - 質問-回答形式がモデルにマッチしていないんかも？

  - 解決案：
    - 必要な計算操作をスクラッチパッドを使って明示的にモデルに教えられるか試してみた
  - 結果：
    - 質問-回答形式とほぼ同様に、見たことある複雑さの問題は解けるが、領域外はダメダメ
      - より広い、より深い計算グラフへの一般化では完全に失敗

    - 図4b参照

  - 結論：
    - スクラッチパッド形式を用いて、計算ステップに関するガイダンスを用いて直接学習した場合でも、領域外の問題は解けるようにはならない
    - **Transformer が問題に逐次的に取り組まざるを得ないという自己回帰的な特性が、モデルにステップバイステップの解を生成するように指示しても解決できない基本的な課題を提示している**ことを示唆している
      - モデルはタスクの厳密なグローバルな理解せずに、次の単語を生成する貪欲なプロセスに依存して予測を行っている
        - 見たことあるものの領域外の複雑さの問題を解くためには、「逐次的に次の単語を予測するTransformer」とは異なる、「タスクを厳密にグローバルに理解する特性を持つモデル」が必要なのではないかということを示唆


## 批評
-

## 次に読むべき論文
-