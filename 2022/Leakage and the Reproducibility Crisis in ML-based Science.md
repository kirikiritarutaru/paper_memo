# Leakage and the Reproducibility Crisis in ML-based Science

## 論文について (掲載ジャーナルなど)
- プリンストン大学のプレプリント
    - https://reproducible.cs.princeton.edu/

- pdf
    - https://reproducible.cs.princeton.edu/irreproducibility-paper.pdf


## 概要
- ML分野の再現性の問題を系統的に調査した論文
    - 17分野で誤りが見つかり、329の論文に影響があり、いくつかの論文では乱暴に楽観的な結論を導いていることがわかった

- 教科書的な誤りから未解決の研究課題まで、8つのタイプの”リーケイジ”を分類して提示する

## 問題設定と解決したこと
- 本論文での**再現可能**の定義:
    - 研究成果を得るために使用したコードとデータが入手可能で、データが正しく解析されていること

- 本論文のContributions
    1.  Leakageの問題の調査と分類
        -   ML手法を採用した研究コミュニティの文献を調査
        -   17分野20件の論文に誤りが見つかり、計329論文に影響があることを発見
        -   Leakageに対する8種類の分類法を提示
    2.  Leakageを検出し、防止するためのモデル情報シート
        -   MLモデルを用いた科学的主張を行う際のチェックシートを作成
            -   上であげた8種類のLeakage全てに対応
    3.  Civil war予測におけるLeakageに関する実証的事例研究
        -   政治学の1分野であるCivil war予測において、「旧来の統計モデルよりもMLモデルのほうが優れている」という主張するすべての論文が再現に失敗することを確認
        -   上述のモデル情報シートでLeakageを発見できることを確認
- Data Leakageに関するこれまでの研究は、主にエンジニアの現場や予測モデリングコンテストにおける「Data Leakage」の軽減に焦点を当てたものだった。これらの設定は科学的研究とは異なっており、モデリングコンテストやMLの工学的応用におけるData Leakageの軽減策は、MLベースの科学におけるData Leakageの軽減策に変換されない
    - モデリングコンペティションにおけるリーク
        - コンペでは、参加者は（基本）評価セットにアクセスできないが
        - MLベースの科学では、研究者はMLモデルを作成するときにデータセット全体にアクセスすることができる問題がある

    - 工学アプリケーションにおけるリーク
        - MLモデルを限定的に実運用し、リークを検出する
            - 特定のプロセスに対する洞察を得ることではなく、製品のコンポーネントの一部として機能するMLモデルだからできる
            - MLモデルの工学的応用は、急速に変化する状況下で動作し、大きなデータセットにアクセスできることが多いので、小さな性能差はそれほど重要ではないことが多い

        - MLベースの科学では、MLモデルの性能を証拠として科学的な主張を行う←問題だよねぇ！
            - 科学的主張はMLモデル間の小さな性能差に敏感


## 何をどう使ったのか
- モデル情報シート
    1.  トレーニングセットとテストセットがキレイに分類されているか
        1.  テストセットがない
        2.  トレーニングセットとテストセットを合わせて前処理してないか
        3.  トレーニングセットとテストセットを合わせて特徴量選択してないか
        4.  データセット内で重複しているデータがないか

    2.  モデルが正規のものではない特徴を使用していないか
        -   例:高血圧を予測するための特徴量として「降圧剤を使用しているか」が含まれているケース
            -   降圧剤を出すかどうかを検討するために高血圧を予測するのに、なんでやねん
            -   降圧剤出されてる時点で高血圧に決まってるやんか

    3.  テストセットは科学的に意味がある分布からひかれているか
        1.  時間的リーク
            -   MLモデルを用いて将来の結果を予測する場合、テストセットには学習セットより前の日付のデータが含まれているべきでない

        2.  トレーニングサンプルとテストサンプル間の依存関係
            -   トレーニングセットのデータとテストセットのデータが同じ人または同じユニットから得られた場合、精度が異常によくなることがあるよね
                -   例:同じ患者からとったデータを使いまわしたりとか

        3.  テストセットのデータ分布のサンプリングバイアス
            -   例:
                -   地理的位置が近いところのデータをテストデータに使う
                -   自閉症の境界例のデータを除外してしまうことで、テストセットが「一般の人々」を代表しなくなり、楽観的な結果を導く

- **一般化できる知識の創造を目指すMLベースの科学では、「この結果はモデルが評価された集団とは異なる集団に一般化できる」という主張は、慎重に受け止めるべき**
- 他の問題
    - 計算機的な再現性の問題
        - 同じ計算を回しても再現できないなど
        - 膨大な計算資源が必要で再現できないこともあるよね

    - データの質の問題
        - データの欠損値に対処していない、予測変数の数に比べてデータセットのサイズが小さいなど

    - メトリックの選択の問題
        - アンバランスなデータセットにaccuracyを使うなど

    - 標準的なデータセットの使用方法の問題
        - トレーに具とテストの分割を固定する/評価メトリックを固定するなど、標準的なモデリングと評価の手順を踏んでない論文あり


## 主張の有効性の検証方法
- civil war prediction のケースで実際にやってみた
    - 


## 批評
- 

## 次に読むべき論文
- 
