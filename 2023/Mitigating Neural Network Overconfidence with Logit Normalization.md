# Mitigating Neural Network Overconfidence with Logit Normalization

## 論文について (掲載ジャーナルなど)
- https://arxiv.org/pdf/2205.09310.pdf

## 概要
- 分布外の入力を検出することは、機械学習モデルを実世界に安全に展開するために重要
- しかしながら、よくしられた課題として、overconfidenceの問題がある
    -  分布内入力と分布外入力の両方に対して異常に高い信頼度を出す問題

- 本研究では、上記問題を緩和する手法を提案する
    - 提案手法：ロジット正規化＝クロスエントロピー損失に対する簡単な修正により、学習時のロジットに一定のベクトルノルムを強制する方法

- ロジット正規化で学習したニューラルネットワークは、分布内データと分布外データの信頼度スコアを区別して出力することができる

## 問題設定と解決したこと
- 

## 何をどう使ったのか
- 

## 主張の有効性の検証方法
- 

## 批評
- 

## 次に読むべき論文
- 
