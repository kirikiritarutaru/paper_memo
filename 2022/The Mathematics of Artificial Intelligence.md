# The Mathematics of Artificial Intelligence

## 論文について (掲載ジャーナルなど)
- [Kutyniok, G. (2022). The Mathematics of Artificial Intelligence. *arXiv preprint arXiv:2203.08890*.](https://arxiv.org/pdf/2203.08890.pdf)
    - ドイツの応用数学者の人みたい（数学ガチ勢の解説ありがたし）


## 概要
- DNNの数学的基盤のいくつかの結果と理論的方向性の提示、主要な未解決問題についての議論
    - 2022年の国際数学者会議の招待講演をベースとする


## 数学×人工知能分野の問題設定
- DNNはおおくの分野でブレークスルーを起こしている
- しかしながら、下記2点が著者は気がかり
    - DNNの実用的な限界がまったく探求されておらず、まだ「何でも屋」として考えられている
    - DNNの包括的な理論的基礎が欠けている
        - NeurlIPSでGoogleのAli Rahimi氏が公園で「機械学習は錬金術の一形態になっている」と述べたことからもわかるやで
- DNNの数学的な基盤がないことで以下の弊害が表れている
    1.  適切なネットワークアーキテクチャの探索に時間がかかり、（アーキテクチャ設計の指針の欠如してる）
    2.  非常に繊細な試行錯誤に基づく学習プロセスとなり、（学習方法の指針がないので細かいTipsまみれになる）
    3.  学習後のネットワークの性能の誤差の範囲がわからなくなり、（汎化性能がわからない）
    4.  入力データにわずかな摂動をを加えただけで、出力が大きく変化し、それまでとは異なる誤った判断をくだしてしまいがち（未知のデータに対するDNNの予測の安定性が低くなる）

- DNNの”ロバスト性”の問題は数学的アプローチによってのみ取り組むことができるよね！

## 主な研究の方向性

- 本稿で議論する、数学×人工知能の分野の研究の方向性
    1.  人工知能のための数学的基礎
        -   人工知能の深い数学的理解を導き出すことを目的とする方向性

    2.  数学的問題のための人工知能
        -   逆問題や偏微分方程式などの数学的問題設定の優れたソルバーを開発するために人工知能の方法論を採用することを目的とする方向性

- DNNの数学的基礎の重要な研究の方向性
    1.  アーキテクチャの選択
    2.  最適化問題
    3.  汎化能力

- DNNの学習過程全体を統計的学習問題として考えると、これら3つの研究の方向性は、「全体の誤差を分析すること」が自然な方向性となる
    - ネットワークの表現力
        - DNNのアーキテクチャの側面がDNNの最良の場合の性能に影響をあたえるかどうか、またどの程度影響を与えるかについての一般的理解

    - 学習/最適化
        - 確率的勾配降下法などの学習アルゴリズムの解析
            - 特に、問題自体が非常に非凸にもかかわらず、なぜ適切なローカルミニマムに収束するのか

    - 汎化
        - 標本外誤差の理解。経験的リスクと実際のリスクの距離を測定する

- 最近では、**説明可能性**というワードがトピックにあがる
    - *現時点未開拓*
    - 学習済みDNNが、入力データのどの特徴が判断に重要か、どのように判断に至るかを深く理解すること

- 人工知能の方法論を使って、数学的問題を解決することを目指す方向性はさらに2つの流れがある
    - 逆問題
        - 逆問題を解くための古典的なモデルベースアプローチを、人工知能の手法を利用することにより改良することを目的とする

    - 偏微分方程式
        - 偏微分方程式の古典的なソルバーを、人工知能のアイデアを用いて改良することを目的とする


## 人工知能分野における主要な数学的未解決問題
- [J. Berner, P. Grohs, G. Kutyniok, and P. Petersen. The Modern Mathematics of Deep Learning. In: Mathe-
    matical Aspects of Deep Learning, Cambridge University Press, to appear.](https://arxiv.org/pdf/2105.04026.pdf)で述べられている人工知能の数学的な7つの重要問題を紹介する
    1.  深さの役割とは？
    2.  DNNのアーキテクチャのどの部分が深層学習の性能に影響を与えるのか？
    3.  非凸問題にもかかわらず、確率的勾配降下法が良いローカルミニマムに収束するのはなぜか？
    4.  なぜ大規模なDNNはオーバーフィットしないのか？
    5.  なぜDNNは超高次元環境で優れた性能を発揮するのか？
    6.  DNNはデータのどのような特徴を学習するのか？
    7.  DNNは自然科学において高度に専門家した数値アルゴリズムを代替できるか？


## 批評
- 俺の数学力がたりねぇ！！！！！

## 次に読むべき論文
- 
