# Deep Neural Networks and Tabular Data: A Survey

## 論文について (掲載ジャーナルなど)
- [Borisov, V., Leemann, T., Seßler, K.,  Haug, J., Pawelczyk, M., & Kasneci, G. (2021). Deep neural networks  and tabular data: A survey. *arXiv preprint arXiv:2110.01889*.](https://arxiv.org/pdf/2110.01889.pdf)

## 概要
- 表敬式のデータに対する最先端の深層学習手法の概要を説明
    - データ変換・特殊なアーキテクチャ・正則化モデルのグループに分類
    - 各グループの主要なアプローチの概要を述べる

- 従来の機械学習手法と深層学習アプローチの実証的な比較
    - DBDTに基づくアルゴリズムの性能は、深層学習アプローチを上回る結果に


## 問題設定と解決したこと
- 画像、音声、テキストデータでは、DNNは高性能
- しかし、**”表形式のデータ”**ではまだまだ
    - なぜ？
        - 密な数値的特徴と疎なカテゴリ特徴をもつ
        - 特徴間の相関は、画像や音声データの空間的・意味的関係よりも弱い
            - 空間情報に頼らずに相関を発見し利用する必要がある

- 表形式のデータは落とし穴多数
    - ノイズ、不確かさ、異なる属性タイプ、値の範囲、値の利用不可能性
        - DNNは柔軟だし効率的で反復的な学習が可能だから対処できるかも？

- 表形式のデータ、特に異種データ（Heterogeneous data）で重要なタスク
    1.  異種データの生成タスク
        - 異種の表形式のデータは収集に多大なコストと時間がかかる

            - 生成して水増ししたらいいんじゃね？
                - 表データ生成は”闇”なので、非常に複雑
                - 最先端のアプローチについてはセクションVで議論

    2.  表形式データに対するDNNの解釈タスク
        - 一般的アプローチは、グループがハイライトされること（saliency マップみたいに）
        - *変数関係の強調*←これが特に重要
            - アテンションメカニズムによって、変数関係を強調（アテンションマップの可視化）

- 本論文における議論の概要
    1.  表形式のデータに対するDNNの既存の論文のレビュー
    2.  異種表形式データの分類と回帰タスクのためのアプローチを分類
    3.  表形式データの生成に向けた技術の現状と展望の提示
    4.  表形式データのためのDNNの既存の説明アプローチの概要（DNNの解釈性）
    5.  複数の実世界の異種表形式データセットにおける従来の機械学習手法とDNNモデルの実証的比較
    6.  表形式データに対するDNNの成功が限定的である主な理由についての考察
    7.  表形式データのDNNに関連する未解決課題のリスト


## 何をどう使ったのか
- 深層学習モデルの中だとTabNetが特に有名
    - TabNetによって、Attentionに基づく手法と自己教師付き学習手法によって、深層学習モデルが表形式のデータに適用されはじめた
    - Transformerをベースとした手法は表形式のデータセットに対して人気になってきている（2022現在）

- 表形式のデータに対しては、DNNは（普通）線形や木ベースといった伝統的な機械学習手法よりも精度が悪くなりがち
    - ↑原因はよくわからないことが多い
    - 考えられる理由
        1.  不適切な学習データ
            -   データの質が悪いケースのこと
                -   欠損値、極端なデータ、誤ったデータ、矛盾したデータ
                -   データから生成される高次元の特徴ベクトルに比べてデータセットのサイズが小さい問題
                -   データの収集にコストがかかるため、クラスが不均衡になる問題

        2.  空間依存性の欠落または、複雑で不規則な空間依存性
            -   表形式のデータセット自体がもつ難しさのこと
                -   変数間に空間的相関がないことが多い
                -   もしくは、特徴間の依存関係が複雑で不規則なことが多い

            -   畳み込みニューラルネットワークは均質なデータ（特に画像データ）のための構造（＝データに置く前提）をもつので、表形式のデータセットのモデル化には適さないことが多い

        3.  広範な前処理
            -   カテゴリ特徴を扱うことの難しさのこと
                -   カテゴリ特徴はほとんどの場合、（最初のステップとして）単純な one-hotベクトルへの変換や 順序エンコーディングをかけて数値表現に変換する
                -   しかし！カテゴリ特徴は非常にまばらなため、↓につながる可能性がある
                    -   one-hotベクトルへの変換した場合：非常にまばらな特徴行列になる
                    -   順序エンコーディングをかけた場合：非順序値の synthetic alignment

            -   DNNの前処理手法を適用すると、元のデータに関する情報を失うことが多く、予測性能の低下につながることもあるやで！

        4.  モデルのSensitivity
            -   DNNの頑健性の低さのこと
                -   DNNは入力データの小さな摂動に対して弱い（カテゴリ特徴の小さな変化が、予測に大きな影響を与える）
                -   決定木系のアルゴリズムは特徴と閾値を選択し、残りを無視するので、例外的に摂動を処理することができる

            -   表形式のデータにDNNを適用する時は、強い正則化をかけると良さげ（セクションⅣ-Cで議論する）
            -   DNNはハイパラが非常に多いので、チューニングに時間がめっちゃかかるし、ハイパラの選択に鋭敏な傾向がある←使いづらい


## 主張の有効性の検証方法
- 

## 批評
- 

## 次に読むべき論文
- [R. Shwartz-Ziv and A. Armon, “Tabular Data: Deep Learning is Not All You Need,” 2021.](https://arxiv.org/pdf/2106.03253.pdf)
    - 表形式データ用の深層学習モデルがいくつか提案されて、XGBoostよりも高性能とかいってるけど本当？
    - いろんなデータセットで比較してみました！→XGBoostのほうが性能いいし、チューニングも簡単だということがわかったで！
        - 深層学習モデルとXGBoostのアンサンブルならワンチャンあるかもな！
- [M. Sahakyan, Z. Aung, and T. Rahwan, “Explainable artificial intelligence for tabular data: A survey,” IEEE Access, 2021.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9551946)
    - 表形式データにおけるXAIのサーベイ論文
