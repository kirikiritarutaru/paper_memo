# On Empirical Comparisons of Optimizers for Deep Learning

## 論文について (掲載ジャーナルなど)

- [Choi, D., Shallue, C. J., Nado, Z., Lee, J., Maddison, C. J., & Dahl, G. E. (2019). On empirical comparisons of optimizers for deep learning. arXiv preprint arXiv:1910.05446.](https://arxiv.org/pdf/1910.05446)

## 概要

- 深層学習における最適化アルゴリズムはパラメータが固定値で実験して比較されてるけど、おかしくないか？というツッコミ論文
- 可能であれば、最適化アルゴリズムの**すべてのパラメータ**を**広い探索範囲**でチューニングすべきと結論づけた
  - とくに、Adamのパラメータ$\epsilon$が従来考えられているよりも結果に影響を与えるのでチューニングしたほうがいいよ

## 感想

- ツッコミ論文すきだわー
  - でもこんなんいちいちチューニングしてられへんという反論もわかる
  - 過剰適合しそうじゃない？汎化性能下がりそうという反論もわかる
- ただ2025年現在ですでにちょっと古いのでもっかいやってほしい
- 検証につかったデータセットとモデルが少ないのが気がかり
  - 結論全然変わりそうではある

## 論文読解プロンプト実行結果

新しい論文「On Empirical Comparisons of Optimizers for Deep Learning.pdf」に関して、論文読解プロンプトを実行します。

### 1. 論文のテーマと目的を要約

- **テーマ**: 本論文は、深層学習におけるオプティマイザの経験的比較の妥当性について検証しています. 特に、ハイパーパラメータのチューニングプロトコルが比較結果に与える影響の大きさを明らかにしています.
- **目的**: 既存の研究におけるオプティマイザのランキングが、不適切なハイパーパラメータチューニングによって歪められている可能性を示し、より現実的なチューニングプロトコルを用いた比較の重要性を主張することです. また、オプティマイザ間の包含関係が実際的な性能比較において重要であることを実証しています.
- **背景**: 深層学習の実務者にとって、適切なオプティマイザの選択はモデルの学習速度と最終的な予測性能を決定する重要なステップです. 理論的な指針が不足している現状では、経験的研究やベンチマークが意思決定の基準となっています. しかし、既存の経験的比較研究（Wilson et al., 2017; Schneider et al., 2019 など）では、特定のハイパーパラメータを固定したまま比較が行われることが多く、その結果の信頼性に対する懸念がありました.
- **提案手法が必要になるまでのストーリー**: 従来のオプティマイザ比較研究では、チューニングするハイパーパラメータの種類や範囲が限られており、それらの制約が比較結果に大きく影響を与える可能性が指摘されていました. 例えば、ADAMなどの適応的勾配法は、一部のパラメータ（εなど）をデフォルト値のまま比較されることが多く、その潜在的な性能が十分に評価されていない可能性がありました. 本論文は、より網羅的なハイパーパラメータチューニングを行うことで、これらの既存研究の結果が覆り、オプティマイザ間の包含関係（より一般的なオプティマイザは、適切にチューニングされれば、その特殊なケースよりも決して性能が悪くならないという関係）が実際にも成り立つことを示す必要性を主張しています.

### 2. 論文のセクション構成を分析

- **1. Introduction (導入)**: オプティマイザ選択の重要性、既存の経験的比較研究の問題点、本論文の目的と貢献を概説します.
- **2. Background and Related Work (背景と関連研究)**: 既存のオプティマイザ比較研究（Wilson et al., 2017; Schneider et al., 2019 など）とその問題点をレビューし、本研究の動機付けを行います.
- **3. What is an optimizer? (オプティマイザとは)**: 第一階最適化アルゴリズムの定義、ハイパーパラメータの役割、オプティマイザ間の包含関係の概念を定義します.
- **4. Experiments (実験)**: さまざまな画像分類と自然言語処理のタスクにおけるオプティマイザの性能を、網羅的なハイパーパラメータチューニングの下で比較した実験結果を提示します.
  - **4.1. Overview of Workloads and Experimental Details (ワークロードと実験の詳細)**: 実験で使用したデータセット、モデル、評価指標、バッチサイズ、学習ステップ数などを説明します.
  - **4.2. Inclusion relationships matter in practice (包含関係は実際にも重要)**: 実験結果を示し、より一般的なオプティマイザはその特殊なケースよりも決して性能が劣らないという包含関係が、実際にも成り立つことを示します.
  - **4.3. Reconciling disagreements with previous work (以前の研究との不一致の解消)**: Wilson et al. (2017) や Schneider et al. (2019) の結果を再現し、ハイパーパラメータチューニングプロトコルを拡張することで、それらの研究で観察されたオプティマイザのランキングが変化し、本研究の主張と一致することを示します.
- **5. Conclusions (結論)**: 本研究の主要な発見、すなわちオプティマイザ間の包含関係の実際的な重要性と、ハイパーパラメータチューニングプロトコルの影響の大きさを改めて強調します. また、今後の研究への示唆や注意点を述べます.
- **A. Optimizer inclusions (オプティマイザの包含)**: 本論文で検討したオプティマイザ間の包含関係を数学的に証明します.
- **B. Workload details (ワークロードの詳細)**: 実験で使用したデータセットとモデルの詳細な設定について説明します.
- **C. Estimating trial outcomes via bootstrap (ブートストラップによる試行結果の推定)**: ハイパーパラメータチューニングの実験結果の統計的評価に用いたブートストラップ法について説明します.
- **D. Hyperparameter Search Spaces (ハイパーパラメータ探索空間)**: 各実験で使用したハイパーパラメータの探索範囲を詳細に記述します.
- **E. Additional plots (追加のプロット)**: 本文中で示しきれなかった追加の実験結果や分析結果をグラフで示します.
- **References (参考文献)**: 本論文で引用した文献リストを掲載します.

### 3. 重要なキーワードと概念を抽出

- **オプティマイザ (Optimizer)**: 深層学習モデルのパラメータを更新し、損失関数を最小化するアルゴリズム（例: SGD, Momentum, Nesterov, RMSProp, Adam, NAdam）.
- **ハイパーパラメータ (Hyperparameter)**: オプティマイザの挙動を制御するパラメータ（例: 学習率、モメンタム係数、ε）.
- **ハイパーパラメータチューニング (Hyperparameter Tuning)**: モデルの性能を最大化するために、適切なハイパーパラメータの値を探索するプロセス.
- **ハイパーパラメータチューニングプロトコル (Hyperparameter Tuning Protocol)**: ハイパーパラメータの探索範囲、探索方法、評価方法など、チューニングの手順や設定.
- **包含関係 (Inclusion Relationship)**: あるオプティマイザが、別のより一般的なオプティマイザの特殊なケースとして近似できる関係性（例: SGD ⊆ Momentum ⊆ Adam）.
- **適応的勾配法 (Adaptive Gradient Methods)**: パラメータごとに学習率を適応的に調整するオプティマイザ（例: RMSProp, Adam, NAdam）.
- **経験的比較 (Empirical Comparison)**: 実際のデータセットとモデルを用いて、異なるオプティマイザの性能を比較すること.
- **ワークロード (Workload)**: モデルとデータセットの組み合わせ.
- **検証精度 (Validation Accuracy)**: ハイパーパラメータチューニングの際に、モデルの汎化性能を評価するために使用する指標.
- **テスト精度 (Test Accuracy)**: 最終的なモデルの性能を評価するために、学習に使用しなかったデータセットで測定する指標.
- **学習率スケジューリング (Learning Rate Scheduling)**: 学習の進行に合わせて学習率を動的に変化させる手法.
- **ε (イプシロン)**: AdamやRMSPropなどの適応的勾配法における、数値的安定性のために分母に加える小さな正の定数. 本論文では、εが性能に大きく影響する可能性を指摘しています.
- **収束 (Convergence)**: 最適化アルゴリズムが、損失関数の局所的または全体的な最小値に近づくこと.
- **計算予算 (Computational Budget)**: ハイパーパラメータチューニングに利用できる計算リソースの量.
- **準ランダム探索 (Quasi-random Uniform Search)**: ハイパーパラメータ空間を効率的に探索するための手法.
- **ブートストラップ法 (Bootstrap Procedure)**: 実験結果の統計的な信頼性を評価するためのリサンプリング手法.

### 4. 図表の意味と役割を説明

- **Table 1: Update rules considered in this work (表 1: 本研究で検討した更新則)**: 本研究で比較対象とした主要なオプティマイザ（SGD, Momentum, Nesterov, RMSProp, Adam, NAdam）のパラメータ更新式を定義しています. 各オプティマイザのハイパーパラメータの記号と役割を理解する上で重要です。
- **Table 2: Summary of workloads used in experiments (表 2: 実験で使用したワークロードの概要)**: 各実験で使用したタスク（画像分類、言語モデリング）、評価指標、モデル、データセット、目標エラー率、バッチサイズ、学習ステップ数の予算をまとめています. 実験設定の全体像を把握するのに役立ちます。
- **Figure 1: The relative performance of optimizers is consistent with the inclusion relationships... (図 1: オプティマイザの相対性能は包含関係と一致する...)**: さまざまなワークロードにおいて、ハイパーパラメータを個別にチューニングした後の、最終的な検証エラーとテストエラーを比較しています. オプティマイザの包含関係（より一般的なオプティマイザは、その特殊なケースよりも性能が悪くならない）が実際にも成り立つことを視覚的に示しています。
- **Figure 2: The relative training speed of optimizers is consistent with the inclusion relationships (図 2: オプティマイザの相対的な学習速度は包含関係と一致する)**: 各ワークロードにおいて、目標の検証エラーに到達するまでの学習ステップ数を比較することで、オプティマイザの学習速度を比較しています. こちらも包含関係と整合的な結果を示しています。
- **Figure 3: Tuning more hyperparameters removes the differences in test error between optimizers observed by Wilson et al. (2017) (図 3: より多くのハイパーパラメータをチューニングすることで、Wilson et al. (2017) が観察したオプティマイザ間のテストエラーの差がなくなる)**: Wilson et al. (2017) の実験設定を再現し、ハイパーパラメータのチューニング範囲を広げることで、彼らの結果とは異なり、オプティマイザ間の性能差が縮まる、あるいはなくなることを示しています. ハイパーパラメータチューニングの重要性を強調する図です。
- **Figure 4: Tuning more hyperparameters changes optimizer rankings from Schneider et al. (2019) to rankings that are consistent with the inclusion relationships (図 4: より多くのハイパーパラメータをチューニングすることで、Schneider et al. (2019) のオプティマイザのランキングが、包含関係と一致するように変化する)**: Schneider et al. (2019) の実験設定を再現し、同様にハイパーパラメータのチューニング範囲を広げることで、彼らの結果とは異なるランキングが得られ、包含関係と整合的になることを示しています.
- **Figure 5: Example plot of final validation error projected onto the axes of the hyperparameter space (図 5: ハイパーパラメータ空間の軸に射影した最終検証エラーの例示プロット)**: ハイパーパラメータの探索空間が適切に設定されていることを示すための例です. 最適なハイパーパラメータの値が探索空間の境界から離れていることを確認しています。
- **Figures 6-8: Validation/Test performance of the best trial mostly converges with as few as ... hyperparameter tuning trials (図 6-8: 最良の試行の検証/テスト性能は、わずか ... 回のハイパーパラメータチューニング試行でほぼ収束する)**: ハイパーパラメータチューニングの試行回数が、性能評価に十分であることを示しています.
- **Figure 9: The relative performance of optimizers is consistent with the inclusion relationships when we select for lowest training loss (図 9: 最低の学習損失で選択した場合でも、オプティマイザの相対性能は包含関係と一致する)**: 検証損失だけでなく、学習損失を基準に選択した場合でも包含関係が成り立つことを示しています.
- **Figure 10: Our results confirming the relevance of optimizer inclusion relationships do not depend on the exact step budgets or error targets we chose (図 10: オプティマイザの包含関係の関連性を確認する我々の結果は、正確なステップ予算やエラー目標に依存しない)**: 実験の設定（ステップ数や目標エラー）を変化させても、包含関係が予測力を持つことを示しています.
- **Tables 3-35: Hyperparameter Search Spaces (表 3-35: ハイパーパラメータ探索空間)**: 各ワークロードとオプティマイザに対して使用した、初期および最終的なハイパーパラメータの探索範囲を詳細に示しています. これらの表は、実験の再現性や設定の理解に不可欠です。
- **Tables 36-47: Hyperparameter Search Ranges (表 36-47: ハイパーパラメータ探索範囲)**: 特定の実験（Wilson et al. (2017) や Schneider et al. (2019) の再現など）で使用したハイパーパラメータの探索範囲を示しています.

### 5. 質問リストの各質問を分析 (ユーザーからの質問を想定)

以下は、論文に関してユーザーが持つ可能性のある質問の例と、その意図、関連する論文の箇所です。

- **質問**: 本論文の主要な主張は何ですか？
  - **意図**: 論文の最も重要な結論を理解したい。
  - **関連箇所**: 1. Introduction, 4.2 Inclusion relationships matter in practice, 5. Conclusions
- **質問**: なぜ既存のオプティマイザ比較研究の結果は信頼できない可能性があるのですか？
  - **意図**: 既存研究の問題点を具体的に知りたい。
  - **関連箇所**: 1. Introduction, 2. Background and Related Work, 4.3 Reconciling disagreements with previous work
- **質問**: オプティマイザ間の「包含関係」とは具体的にどういう意味ですか？
  - **意図**: 論文の重要な概念を深く理解したい。
  - **関連箇所**: 3. What is an optimizer?, 3.1. The taxonomy of first-order methods, Definition 1 (Inclusion relationship), Appendix A. Optimizer inclusions
- **質問**: ハイパーパラメータチューニングは、オプティマイザの比較においてなぜ重要なのでしょうか？
  - **意図**: ハイパーパラメータチューニングの役割とその影響を理解したい。
  - **関連箇所**: 1. Introduction, 4. Experiments, 4.3 Reconciling disagreements with previous work, 5. Conclusions
- **質問**: 本論文では、どのようなデータセットとモデルを使って実験を行っていますか？
  - **意図**: 実験の範囲と設定の詳細を知りたい。
  - **関連箇所**: 4.1. Overview of Workloads and Experimental Details, Table 2, Appendix B. Workload details
- **質問**: Adamは常にMomentumやSGDよりも性能が良いということですか？
  - **意図**: 実験結果の具体的な解釈と、一般的なオプティマイザの優劣について理解したい。
  - **関連箇所**: 4.2. Inclusion relationships matter in practice, 5. Conclusions, Figure 1, Figure 2
- **質問**: Adamのハイパーパラメータであるεは、性能にどのような影響を与えるのですか？
  - **意図**: 特定のハイパーパラメータの役割とそのチューニングの重要性を理解したい。
  - **関連箇所**: 2. Background and Related Work, 4.2. Inclusion relationships matter in practice, 4.3. Reconciling disagreements with previous work, 5. Conclusions, Tables 6-8, 12-14, 18-20, 24-26, 29, 30, 34, 35, 39, 41, 44, 47
- **質問**: Wilson et al. (2017) や Schneider et al. (2019) の研究結果と、本論文の結果が異なるのはなぜですか？
  - **意図**: 既存研究との矛盾点を理解し、本論文の貢献を明確にしたい。
  - **関連箇所**: 2. Background and Related Work, 4.3 Reconciling disagreements with previous work, Figure 3, Figure 4
- **質問**: 本論文の実験におけるハイパーパラメータの探索範囲はどのように決定されたのですか？
  - **意図**: 実験の信頼性と妥当性を評価したい。
  - **関連箇所**: 4. Experiments, Appendix D. Hyperparameter Search Spaces
- **質問**: 実務者がオプティマイザを選択する際に、本論文からどのような示唆が得られますか？
  - **意図**: 論文の結論を実際の応用場面に結び付けたい。
  - **関連箇所**: 5. Conclusions, 43

### 6. 各質問に対する回答を生成

以下に、前項で想定した質問に対する回答を論文の内容に基づいて生成します。

- **質問**: 本論文の主要な主張は何ですか？

  - **回答**: 本論文の主要な主張は、**深層学習におけるオプティマイザの経験的比較は、ハイパーパラメータのチューニングプロトコルに非常に敏感である**ということです. 著者らは、より現実的なチューニングを行うことで、**より一般的なオプティマイザはその特殊なケースよりも決して性能が悪くならない**という包含関係が実際にも成り立つことを示しています. したがって、既存の研究におけるオプティマイザのランキングは、不十分なハイパーパラメータチューニングによって誤解を招く可能性があると指摘しています.

- **質問**: なぜ既存のオプティマイザ比較研究の結果は信頼できない可能性があるのですか？

  - **回答**: 既存のオプティマイザ比較研究（Wilson et al., 2017; Schneider et al., 2019 など）では、**一部のオプティマイザのハイパーパラメータをデフォルト値に固定したまま、主要なハイパーパラメータ（主に学習率）のみをチューニングして比較している**ことが多いからです. 本論文の著者らは、このような限定的なチューニングプロトコルでは、オプティマイザの潜在的な性能を十分に引き出せず、**不公平な比較になる可能性**があると指摘しています. また、重要なハイパーパラメータ（例えば、ADAMのε）を適切にチューニングしないことが、誤った結論につながることも示唆しています.

- **質問**: オプティマイザ間の「包含関係」とは具体的にどういう意味ですか？

  - **回答**: オプティマイザ間の「包含関係」とは、**あるオプティマイザ（特殊なケース）が、別のより一般的なオプティマイザのハイパーパラメータを特定の範囲に設定することで、その挙動を近似できる**という関係を指します. 例えば、SGDはMomentumのモメンタム係数γを0に設定することで完全に一致するため、SGDはMomentumに含まれる（SGD ⊆ Momentum）と言えます. 同様に、Momentumは、ADAMの特定のハイパーパラメータ（例えば、εを非常に大きくする）を設定することで近似できるため、MomentumはADAMに含まれる（Momentum ⊆ ADAM）と考えることができます. このような包含関係がある場合、**適切にハイパーパラメータがチューニングされれば、より一般的なオプティマイザはその特殊なケースよりも決して性能が悪くなることはない**はずです.

- **質問**: ハイパーパラメータチューニングは、オプティマイザの比較においてなぜ重要なのでしょうか？

  - **回答**: ハイパーパラメータチューニングは、**各オプティマイザが持つ潜在的な最高の性能を引き出すために不可欠**だからです. オプティマイザの性能は、そのハイパーパラメータの設定に大きく依存します. もし一部のハイパーパラメータを固定したまま比較した場合、その固定された値が特定のオプティマイザにとって最適ではない可能性があり、結果としてそのオプティマイザの性能が過小評価されてしまうことがあります. 本論文は、**公平なオプティマイザの比較を行うためには、各オプティマイザの全ての利用可能なハイパーパラメータを、それぞれのオプティマイザに最適な範囲で独立にチューニングする必要がある**と主張しています.

- **質問**: 本論文では、どのようなデータセットとモデルを使って実験を行っていますか？

  - **回答**: 本論文では、**画像分類タスク**と**言語モデリングタスク**の2種類のタスクで実験を行っています. _ **画像分類タスク**: Fashion MNIST（Simple CNN）、CIFAR-10（ResNet-32, VGG-16）、CIFAR-100（CNN）、ImageNet（ResNet-50）を使用しています. _ **言語モデリングタスク**: Tolstoy's War and Peace（LSTM）、LM1B（Transformer）を使用しています. これらのデータセットとモデルは、深層学習の分野で広く用いられているものです.

- **質問**: Adamは常にMomentumやSGDよりも性能が良いということですか？

  - **回答**: 本論文の実験結果からは、**適切にハイパーパラメータをチューニングした場合、より一般的なオプティマイザはその特殊なケースよりも決して性能が劣らない**という傾向が見られました. AdamはMomentumやSGDを近似できるより一般的なオプティマイザであるため, **適切にチューニングされれば、MomentumやSGDと同等以上の性能を発揮する**ことが実験的に示唆されています [4, 33, Figure 1, Figure 2]. しかし、**特定のワークロードやチューニングが不十分な場合には、必ずしもAdamが常に最良であるとは限りません**. 重要なのは、個々のタスクに対して適切なハイパーパラメータチューニングを行うことと、オプティマイザ間の包含関係を考慮することです.

- **質問**: Adamのハイパーパラメータであるεは、性能にどのような影響を与えるのですか？

  - **回答**: Adamのハイパーパラメータであるεは、**通常は数値的安定性のために非常に小さなデフォルト値（例: 10⁻⁸）に設定されますが、本論文の研究では、εが性能に有意な影響を与える可能性が示唆されています**. 著者らは、さまざまなワークロードにおいて、最適なεの値がデフォルト値から大きく異なる場合があることを発見しました. εは、自然勾配降下法の対角近似におけるダンピング項、信頼領域半径の設定、モメンタムと対角自然勾配降下法の間の補間を制御する役割など、複数の解釈が可能であり、**最適な値は問題に依存する**と考えられます. したがって、**Adamを使用する際には、学習率などの他のハイパーパラメータと同様に、εも適切にチューニングすることが重要である**と結論付けています. 既存研究ではεをデフォルト値のまま比較していることが多いことに対し、本論文は疑問を呈しています.

- **質問**: Wilson et al. (2017) や Schneider et al. (2019) の研究結果と、本論文の結果が異なるのはなぜですか？

  - **回答**: 本論文の著者らは、Wilson et al. (2017) や Schneider et al. (2019) の研究と結果が異なる主な理由は、**ハイパーパラメータのチューニングプロトコルの違い**にあると結論付けています. これらの先行研究では、**チューニングするハイパーパラメータの種類や範囲が限定的**であり、特にAdamなどの適応的勾配法のεパラメータをデフォルト値に固定したまま比較していました. 本論文では、より**包括的なハイパーパラメータチューニング**（学習率だけでなく、モメンタム係数やεなども含めて独立にチューニング）を行うことで、これらの先行研究で観察されたオプティマイザのランキングが変化し、**より一般的なオプティマイザがその特殊なケースよりも決して性能が劣らない**という包含関係と一致する結果が得られました. Figure 3とFigure 4は、チューニング範囲を広げることで先行研究の結果が覆る様子を示しています.

- **質問**: 本論文の実験におけるハイパーパラメータの探索範囲はどのように決定されたのですか？

  - **回答**: 本論文の実験におけるハイパーパラメータの探索範囲は、**まず比較的広い探索空間で初期実験を行い、その結果に基づいて最終的な探索空間を絞り込む**という手順で決定されました. 著者らは、各オプティマイザに対して**個別の探索空間**を設定し、同様の名前を持つハイパーパラメータでも、オプティマイザによって最適な値の範囲が異なる可能性を考慮しました. 探索は対数スケールで行われることが多く、効率的な探索のために工夫されたパラメータの組み合わせ（例: (ε, α₀/√ε) for RMSProp, (ε, α₀/ε) for Adam and NAdam）も用いられています. 最終的な探索空間は、最適なハイパーパラメータの値が探索空間の境界から離れていることを確認することで検証されました [26, Figure 5].

- **質問**: 実務者がオプティマイザを選択する際に、本論文からどのような示唆が得られますか？
  - **回答**: 本論文から実務者がオプティマイザを選択する際に得られる主な示唆は以下の通りです:
    - **利用可能な計算リソースが許す限り、人気のある適応的勾配法（Adam, RMSProp, NAdam）の全てのハイパーパラメータをチューニングすべき**です.
    - 異なるオプティマイザ間で類似した役割を持つハイパーパラメータであっても、最適な値の範囲は異なる可能性があるため、**個別に探索する必要がある**.
    - 特にAdamのεパラメータは性能に影響を与える可能性があり、**デフォルト値に固執せず、チューニングを試みるべき**です.
    - 論文などで提示されているオプティマイザの経験的比較結果を鵜呑みにせず、特に**より一般的なオプティマイザがその特殊なケースよりも性能が劣るという結果には懐疑的であるべき**です.
    - オプティマイザの比較を行う際には、**使用したハイパーパラメータの探索空間と、チューニングを行ったハイパーパラメータの種類を明確に報告する**ことが重要です.

### 7. 論文の論理構造の分析

本論文は、**既存の深層学習オプティマイザの経験的比較研究における方法論的な問題点（特に不十分なハイパーパラメータチューニング）を指摘し、その結果として得られたオプティマイザのランキングの信頼性に疑問を投げかけています**。

1.  **問題提起**: 既存研究では、一部のハイパーパラメータを固定したままオプティマイザを比較している.
2.  **理論的根拠**: より一般的なオプティマイザは、適切にチューニングされれば、その特殊なケースを近似できるため、性能が劣ることはないはずである（包含関係）.
3.  **実験的検証**: さまざまなワークロードにおいて、全ての利用可能なハイパーパラメータを広範囲にチューニングしてオプティマイザを比較実験を行う.
4.  **主要な発見**: 実験の結果、適切にチューニングを行えば、より一般的なオプティマイザはその特殊なケースよりも決して性能が劣らないという包含関係が実際にも成り立つことを示す [33, Figure 1, Figure 2]. また、Adamのεなどの、これまで十分にチューニングされてこなかったハイパーパラメータの重要性を示す.
5.  **既存研究との矛盾の解消**: 既存研究（Wilson et al., 2017; Schneider et al., 2019）の設定を再現し、ハイパーパラメータのチューニング範囲を広げることで、それらの研究で観察されたオプティマイザのランキングが変化し、本研究の主張と一致することを示す [37, 38, 39, 40, Figure 3, Figure 4].
6.  **結論と示唆**: 経験的比較研究の重要性を認めつつも、ハイパーパラメータチューニングの重要性を強調し、今後の研究や実務におけるオプティマイザの選択と評価に対する提言を行う.

論文全体として、**既存の経験的比較に対する批判的視点を提示し、より厳密な実験的方法論の必要性を主張し、包含関係という理論的視点と実験的証拠を結びつける**ことで、深層学習におけるオプティマイザの理解を深めることを目指しています。

### 8. 参考文献の分析

参考文献リスト（）を分析すると、本論文が以下のような研究領域に立脚していることがわかります。

- **深層学習における最適化アルゴリズム**: SGD, Momentum, Nesterov, RMSProp, Adam, NAdam など、様々な第一階最適化アルゴリズムの提案論文や理論的解析に関する研究 [e.g., 53, 50, 57].
- **経験的比較研究**: 既存のオプティマイザの性能を実験的に比較した研究 [e.g., 57, 54]. 本論文はこれらの研究を批判的に検証しています。
- **ハイパーパラメータ最適化**: 機械学習モデルのハイパーパラメータを効率的に探索・最適化する手法に関する研究 [e.g., 45, 55]. 本論文における網羅的なハイパーパラメータチューニングの重要性を裏付ける背景となっています。
- **深層学習のベンチマーク**: 深層学習アルゴリズムの性能を公平に評価するためのベンチマークスイートに関する研究 [e.g., 54]. 本論文は、ベンチマークにおけるハイパーパラメータ設定の重要性を指摘しています。
- **大規模学習**: 大規模なデータセットやモデルを用いた深層学習に関する研究 [e.g., 48, 53]. 実験で使用されたImageNetなどの大規模データセットを用いた研究も引用されています。
- **正則化**: L2正則化 [e.g., 82] など、モデルの汎化性能を向上させるための正則化手法に関する研究。実験設定にも組み込まれています。

これらの参考文献から、本論文が深層学習の最適化という重要なテーマに対して、既存の研究を踏まえつつ、より厳密な実験的検証と理論的考察を行っていることが伺えます。特に、批判的に検討している Wilson et al. (2017) や Schneider et al. (2019) の研究は、本論文のモチベーションと主張を理解する上で重要です。また、Adam や RMSProp の原論文も、これらのオプティマイザの特性と本論文における議論を把握するために重要です。

### 9. 関連研究との比較

本論文は、主に **Wilson et al. (2017)** と **Schneider et al. (2019)** の研究を関連研究として取り上げ、それらの研究結果と本論文の結果を詳細に比較しています.

- **Wilson et al. (2017)** は、単純な分類問題や実際の深層学習ワークロードにおいて、適応的勾配法（Adamなど）が標準的な勾配法（SGD）よりも性能が劣る場合があることを示しました. しかし、本論文では、Wilson et al. (2017) の実験では学習率と学習率減衰のみをチューニングし、Adamのεなどの他の重要なハイパーパラメータをデフォルト値に固定していた点を批判しています. 本論文の実験では、より広範囲のハイパーパラメータをチューニングすることで、AdamがSGDやMomentumよりも決して性能が劣らないことを示し、Wilson et al. (2017) の結果とは異なる結論を得ています.
- **Schneider et al. (2019)** は、深層学習オプティマイザのベンチマークスイート（DEEPOBS）を用いて、さまざまなワークロードでオプティマイザの性能を比較しましたが、主に学習率のみをチューニングし、他のハイパーパラメータは固定していました. 本論文では、Schneider et al. (2019) の実験設定を再現し、より多くのハイパーパラメータをチューニングすることで、彼らの研究で観察されたオプティマイザのランキングが変化し、包含関係と一致するようになることを示しています [38, 39, 40, Figure 4]. 例えば、Schneider et al. (2019) ではAdamがMomentumよりも性能が劣るという結果が得られましたが、より多くのハイパーパラメータをチューニングした本論文の実験では、AdamがMomentumよりも良好な性能を示す結果が得られています [40, Figure 4].

本論文の**新規性**と**貢献**は、これらの先行研究における**不十分なハイパーパラメータチューニングが、オプティマイザの公平な比較を妨げている可能性を具体的に示し、より現実的なチューニングプロトコルを用いた実験によって、オプティマイザ間の包含関係が実際にも重要であることを実証した**点にあります. また、Adamのεなどのこれまで軽視されてきたハイパーパラメータの役割を強調し、今後のオプティマイザの比較研究や実務におけるハイパーパラメータチューニングの重要性を提唱しています.

### 10. 回答の評価

上記の各回答は、対応する質問に対して、論文の内容に基づいた正確かつ詳細な情報を提供していると考えられます。論文中の具体的な記述や図表を参照しながら説明することで、回答の信頼性を高めています。専門用語や複雑な概念については、可能な限り分かりやすく説明するように努めました。

### 11. 提案手法の全体概要と詳細説明

本論文における「提案手法」とは、**深層学習オプティマイザの経験的比較を行うための、より厳密な方法論**を指します。その全体概要は以下の通りです。

- **各オプティマイザに対して、利用可能な全てのハイパーパラメータをチューニングする**.
- **個々のオプティマイザに最適な探索空間を独立に設定する**.
- **現実的な計算予算を想定し、数十から数百の試行を行う**.
- **準ランダム探索などの効率的な探索手法を用いる**.
- **検証セットを用いてハイパーパラメータを評価し、最適な設定を選択する**.
- **オプティマイザ間の包含関係を考慮した上で結果を解釈する**.
- **学習率スケジューリングなどの、現実的な学習パイプラインの要素も考慮に入れる**.
- **実験結果の統計的信頼性を評価するために、ブートストラップ法を用いる**.
- **比較対象の既存研究の結果を再現し、ハイパーパラメータチューニングの範囲を広げることで結果がどのように変化するかを示す**.

詳細については、論文のセクション 4「Experiments」で具体的な実験設定、チューニングプロトコル、使用したハイパーパラメータの探索空間（Appendix D）などが詳細に説明されています。例えば、著者らは、Wilson et al. (2017) の実験を再現する際に、彼らが使用したコードを利用し、同様の学習率のグリッドサーチを行っています. その後、チューニングするハイパーパラメータの種類（モメンタム係数γ、εなど）を増やし、ランダムサーチを用いることで、結果がどのように変化するかを検証しています. 同様に、Schneider et al. (2019) の実験を再現する際には、彼らが主に学習率のみをチューニングしていたのに対し, 本論文では他のオプティマイザ固有のハイパーパラメータも同時にチューニングすることで、結果の変化を分析しています. 使用したハイパーパラメータの探索範囲は、Appendix Dの各表に詳細に記載されており、対数スケールでの探索や、効率的な探索のためのパラメータの組み合わせなどが示されています.

### 12. 提案手法の優位な点と批判されるべき点

**優位な点**:

- **より現実的な実践に近いチューニングプロトコル**: 深層学習の実務者が実際に行う可能性のある、より多くのハイパーパラメータを同時にチューニングするという状況をモデル化しています.
- **オプティマイザ固有の探索空間**: 各オプティマイザの特性に合わせて、最適なハイパーパラメータの範囲を独立に探索することで、潜在的な性能をより引き出すことができます.
- **包含関係の考慮**: オプティマイザ間の理論的な関係性を踏まえた上で実験結果を解釈することで、より深い洞察を得ることができます.
- **既存研究との直接的な比較と矛盾点の解明**: 先行研究の結果を再現し、方法論の違いが結果に与える影響を具体的に示すことで、議論の透明性と説得力を高めています.
- **εパラメータの重要性の強調**: これまで十分に議論されてこなかったAdamなどのεパラメータの性能への影響を示唆し、今後の研究や実務における注意点を喚起しています.

**批判されるべき点**:

- **計算コストの高さ**: 全てのハイパーパラメータを広範囲にチューニングするため、実験に必要な計算コストが大きくなる可能性があります.
- **探索空間の設計の難しさ**: 各オプティマイザに最適な探索空間をどのように決定するのかという点には、依然として主観的な要素や試行錯誤が必要となる可能性があります.
- **バッチサイズの影響の未検証**: 本論文ではバッチサイズを固定しており、バッチサイズの変化がオプティマイザの相対性能やハイパーパラメータの最適値に与える影響については検証されていません. 参考文献 ではバッチサイズの影響が議論されており、今後の研究課題として残されています。
- **ワークロードの限定性**: 実験で使用したデータセットやモデルは一般的なものですが、全ての種類の深層学習タスクやアーキテクチャを網羅しているわけではありません.
- **学習率スケジュールのパラメータ化**: 学習率の減衰スケジュールを特定の形式に限定しているため、他のスケジュールの影響については不明です.

上記を以て、論文読解プロンプトの実行を完了します。

## 追加質問

    オプティマイザ間の関係性（包含関係など）・位置づけについて明示的に述べて。
    また、論文でチューニングすべきと主張されているパラメータについて述べて。

この論文では、深層学習におけるオプティマイザ間の関係性とその位置づけ、そして適切にチューニングすべきパラメータについて明確に述べられています。

オプティマイザ間の関係性（包含関係など）・位置づけについて：

論文では、一般的な**一階の最適化アルゴリズムが自然な包含関係の階層を形成する**と指摘しています。具体的には、以下の包含関係が示されています。

- **SGD ⊆ MOMENTUM**：勾配降下法（SGD）は、モメンタムのモメンタムパラメータ $\gamma$ を0に設定することで、モメンタム法（MOMENTUM）として正確に実装できるため、SGDはMOMENTUMの特殊なケースです。
- **SGD ⊆ NESTEROV**：同様に、Nesterov法（NESTEROV）もパラメータ $\gamma$ を0に設定することでSGDとして正確に実装できるため、SGDはNESTEROVの特殊なケースです。
- **MOMENTUM ⊆ RMSPROP**：RMSPropは、パラメータ $\rho$ を1、$\epsilon$ を0に設定することで、モメンタム法を正確に実装できます。
- **NESTEROV ⊆ NADAM**：NADAMは、$\epsilon$ を非常に大きくすることで、Nesterov法を近似的にシミュレートできます。
- **MOMENTUM ⊆ ADAM**：ADAMも、$\epsilon$ を非常に大きくすることで、モメンタム法を近似的にシミュレートできます。

これらの包含関係から、**より一般的なオプティマイザは、その特殊なケースであるオプティマイザよりも、適切にハイパーパラメータをチューニングすれば、決して性能が劣ることはない**と論じられています。例えば、最適にチューニングされたADAMは、最適にチューニングされたMOMENTUMよりも悪くなることはありません。しかし、ハイパーパラメータの数が多いほどチューニングが難しくなる可能性も指摘されています。

論文では、Wilson et al. (2017) や Schneider et al. (2019) などの既存研究では、ハイパーパラメータのチューニングが不十分であったために、この包含関係と矛盾するような実験結果が得られていたと批判しています。

論文でチューニングすべきと主張されているパラメータについて：

論文では、特に**適応的勾配法（ADAM、RMSProp、NADAMなど）のε（イプシロン）パラメータをチューニングすることの重要性**を強く主張しています。

- 多くの既存研究では、ADAMの $\epsilon$ は $10^{-8}$、RMSPropの $\epsilon$ は $10^{-10}$ という**デフォルト値のまま実験が行われている**ことが一般的であると指摘されています。
- しかし、著者らの実験では、**良好な結果を得るためには、この $\epsilon$ パラメータをデフォルト値から数桁大きくする必要がある場合があった**ことが示されています。ResNet-50 on ImageNetの実験では、NADAMで $\epsilon = 9475$ という非常に大きな値を設定することで、高い検証精度を達成しています。
- $\epsilon$ は、**数値的安定性のために導入された小さな定数**と一般的に認識されていますが、ADAMを自然勾配降下法の対角近似と解釈すると、**Fisher情報行列の条件数を改善する多目的ダンピング項**として捉えることもできます。また、**信頼領域半径の設定や、モメンタムと対角自然勾配降下法の間の補間を制御する**役割も持つと解釈できます。
- これらの解釈に基づくと、**最適な $\epsilon$ の値は問題に依存する可能性が高く、チューニングによって性能向上が期待できる**と結論付けています。

さらに、論文では、**学習率 $(\eta_t, \alpha_t)$、モメンタムパラメータ $(\gamma, \beta_1)$、RMSPropの減衰率 $\rho$、ADAMの二乗勾配の減衰率 $\beta_2$ など、利用可能な全てのハイパーパラメータをチューニングすべきである**と提言しています。特に、異なるオプティマイザ間で同様の役割を持つように見えるハイパーパラメータであっても、最適な値は互いに依存し合うため、個別にチューニングする必要があると強調しています。

総じて、この論文は、オプティマイザの性能比較においては、**適切なハイパーパラメータチューニングプロトコルが非常に重要であり、特に適応的勾配法のεパラメータを含む全てのハイパーパラメータをチューニングすることで、オプティマイザ間の包含関係が実験的にも成り立つ**ことを示唆しています。

---

    論文中で提案されている「より現実的な実践に近いチューニングプロトコル」について詳細に述べてください。

この論文では、深層学習におけるオプティマイザの比較において、**ハイパーパラメータのチューニングプロトコルが非常に重要である**と主張されており、より現実的な実践に近いチューニングプロトコルが提案されています。従来の経験的比較研究（Wilson et al., 2017, Schneider et al., 2019など）では、一部のオプティマイザハイパーパラメータをデフォルト値に固定し、主に学習率のみをチューニングしていたため、不公平な比較が行われていた可能性があると指摘しています。

論文で提案されている「より現実的な実践に近いチューニングプロトコル」の主な特徴は以下の通りです。

- **全ての利用可能なオプティマイザハイパーパラメータのチューニング**: 実務者が通常行うように、学習率だけでなく、モメンタム $(\gamma, \beta_1)$、RMSProp の減衰率 $(\rho)$、ADAM の二乗勾配の減衰率 $(\beta_2)$、そして特に**適応的勾配法（ADAM、RMSProp、NADAM）の $\epsilon$ パラメータを含む全てのハイパーパラメータをチューニングする**ことが重要であると強調されています。論文中の Table 1 に示されているように、各オプティマイザが持つ固有のハイパーパラメータを個別に調整することが前提となっています。
- **オプティマイザ固有のサーチスペース**: 異なるオプティマイザ間で同様の名前を持つハイパーパラメータであっても、最適な値は異なる可能性が高いため、「同じ」サーチスペースを全てのオプティマイザに使用するのではなく、**オプティマイザごとに独立したサーチスペースを設定する**ことが推奨されています。論文の付録 D に、実験で使用された各オプティマイザとワークロードに対する具体的なハイパーパラメータのサーチスペースが記載されています。
- **効率的な探索方法**: ハイパーパラメータの探索には、準ランダム一様探索（quasi-random uniform search）が用いられています。これにより、限られた試行回数の中で効率的に有望なハイパーパラメータの組み合わせを見つけることが期待されます。
- **検証セットによる評価**: チューニングされたハイパーパラメータの性能は、**検証セットでの性能（例えば、検証損失や検証精度）を最大化する**ように評価されます。これにより、過学習を防ぎ、汎化性能の高いモデルを得ることを目指します。
- **複数回の試行と統計的評価**: 各ワークロードに対して数十回から数百回の個別の試行を行い、その結果に基づいてオプティマイザの性能を評価しています。結果の信頼性を高めるために、ブートストラップ法を用いて平均と不確実性を推定しています。

特に、論文では**適応的勾配法における $\epsilon$ パラメータのチューニングの重要性**が強く主張されています。多くの既存研究では、ADAM の $\epsilon$ は $10^{-8}$、RMSProp の $\epsilon$ は $10^{-10}$ というデフォルト値がそのまま使用されていましたが、著者らの実験では、**良好な結果を得るためには、この $\epsilon$ パラメータをデフォルト値から数桁大きくする必要がある場合があった**ことが示されています。例えば、ResNet-50 on ImageNet の実験では、NADAM で $\epsilon = 9475$ という非常に大きな値を設定することで、高い検証精度を達成しています。

$\epsilon$ は一般的に数値的安定性のために導入された小さな定数と認識されていますが[11, 12注釈1]、ADAM を自然勾配降下法の対角近似と解釈すると、**Fisher 情報行列の条件数を改善する多目的ダンピング項**として捉えることもできます。また、**信頼領域半径の設定や、モメンタムと対角自然勾配降下法の間の補間を制御する**役割も持つと解釈できます。これらの解釈に基づくと、**最適な $\epsilon$ の値は問題に依存する可能性が高く、チューニングによって性能向上が期待できる**と結論付けています。

論文では、Wilson et al. (2017) や Schneider et al. (2019) の研究で報告された、適応的勾配法が従来の勾配法やモメンタム法よりも性能が劣るという結果は、**ハイパーパラメータのチューニングが不十分であったことが主な原因である**と指摘しています。著者らがより広範なハイパーパラメータサーチスペースでチューニングを行った結果、より一般的なオプティマイザはその特殊なケースであるオプティマイザよりも決して性能が劣らないという、オプティマイザ間の包含関係と矛盾しない結果が得られています。

結論として、この論文は、オプティマイザの性能を正しく評価するためには、**全ての関連するハイパーパラメータを、オプティマイザ固有のサーチスペースを用いて、適切なチューニングプロトコルに基づいて評価することが不可欠である**と主張しています。特に、適応的勾配法の $\epsilon$ パラメータは、デフォルト値に固執せず、問題に応じて適切にチューニングすべき重要なハイパーパラメータであると強調しています。

---

    準ランダム一様探索（quasi-random uniform search）とブートストラップ法について詳細に説明して。

この論文では、ハイパーパラメータのチューニングと実験結果の評価において、準ランダム一様探索（quasi-random uniform search）とブートストラップ法が用いられています。

**準ランダム一様探索（quasi-random uniform search）について**

- 論文中で、ハイパーパラメータの探索方法として**準ランダム一様探索（quasi-random uniform search）**が使用されたと述べられています。具体的には、与えられたサーチスペース（探索空間）から、**準ランダムな手法を用いてハイパーパラメータの値を一様にサンプリングする**方法です。
- 従来のランダム探索と比較して、準ランダム探索は、**より少ない試行回数で探索空間を効率的にカバーできる**とされています。これにより、限られた計算資源の中で、より良いハイパーパラメータの組み合わせを見つけやすくなる可能性があります。
- 論文の28ページでは、ハイパーパラメータの値は準ランダム一様探索（Bousquet et al., 2017）を用いてサンプリングされ、実行可能な試行（有限の訓練損失を達成した試行）が一定数得られるまで探索が続けられたと説明されています。

**ブートストラップ法について**

- 論文では、ハイパーパラメータチューニングの結果から得られた統計量（例えば、検証誤差やテスト誤差の平均値）の**平均と不確実性を推定するために、ブートストラップ法**が用いられたと説明されています。
- 具体的な手順は以下の通りです:
  1.  まず、各ワークロードに対して$N$回のハイパーパラメータチューニングの試行が行われます（$N$はワークロードによって異なります）。
  2.  ブートストラップの各サンプルにおいて、$N$回の試行結果のデータセットから**重複ありで$N$個の試行結果を再サンプリング**します。
  3.  再サンプリングされたデータセットの**最初の$K$個の試行結果**を用いて、目的の統計量（例えば、最適な検証誤差）を計算します（$K$は事前に設定された、性能評価に使用する試行回数です）。
  4.  上記2と3のプロセスを**100回**繰り返し、100個の統計量のブートストラップサンプルを収集します。
  5.  収集されたブートストラップサンプルから、**平均値、5パーセンタイル、95パーセンタイル**を計算し、これらを結果の平均値と不確実性（誤差範囲）として使用します。
- このブートストラップ法を用いることで、**限られた試行回数で得られた結果の信頼性を評価**し、結果のばらつきや不確実性を定量的に示すことができます。論文中の多くの図で示されている誤差棒は、このブートストラップ法によって推定された90%信頼区間（5パーセンタイルから95パーセンタイルまで）を表しています。

論文の付録C（69ページ）には、このブートストラップ手順の詳細が記載されており、各ワークロードにおける$K$と$N$の値も示されています。また、図3の左側のパネルについては、比較可能性を確保するために、Wilson et al. (2017) の研究と同様の手順が用いられ、ブートストラップ法とは異なる方法で不確実性が評価されています。
