# Why do tree-based models still outperform deep learning on tabular data?

## 論文について (掲載ジャーナルなど)
- https://arxiv.org/pdf/2207.08815.pdf

## 概要
- ディープラーニングはテキストと画像のデータセットで大きな進歩が見られたが、表形式のデータでは優位性は明らかでない
- 本論文ではディープラーニング手法とXGBoostやランダムフォレストなど木ベースのモデルのベンチマークを提供
- 実験する中で、表形式に特化したニューラルネットワークを構築するための指針となる課題を導き出した。

## 問題設定と解決したこと
- 深層学習手法は本当に性能向上しているのか？調べてみました
    - 45の表形式のデータセットで検証
    - ベンチマーク方法も定義

- 結果:
    - Treeベースモデルのほうが処理速度も精度もいいぞ！
    - 表形式のデータに特化したNNの構築の指針を提案するぞ
        1.  有益でない特徴に頑健なモデルであること
        2.  データのorientationを保持するモデルであること
        3.  不規則な関数を容易に学習できるモデルであること


## 何をどう使ったのか
- 表形式データの”均質化”
    - 45個の表形式データセットを以下の基準で選択
        1.  異種カラムであること
            -   列は異なる性質の特徴に対応すること
        2.  高次元でないこと
        3.  文書化されていないデータセットであること（？）
            -   情報が少なすぎるデータセットは除外
        4.  I.I.D なデータセットであること
        5.  実世界のデータセットであること
        6.  小さすぎないこと
            -   特徴数＜4、サンプル数＜3000のデータセットは除外
        7.  簡単すぎないこと
            -   ロジスティック回帰でほぼわけられるような簡単なデータセットは除外
        8.  決定論的でないこと
            1.  チェスとかポーカーのようなゲームのデータセットを除外
        9.  中規模なデータセットであること
            -   10000サンプル程度（50000サンプルの大規模データセットについては別途検討）
        10.  欠損データがないこと
        11.  クラスのバランスがとれていること
             -   対象が複数のクラスである場合、最も多い2つのクラスを取ることによって2値化し、各クラスにサンプルの半分をふる
        12.  低カーディナリティカテゴリ特徴
             -   20項目異常のカテゴリ特徴を除外
        13.  高カーディナリティ数値特徴
             -   10個以下の一意な値をもつ数値特徴を除外
- ハイパーパラメータチューニングを探索するベンチマーク手順
    - ハイパラチューニングの探索が少ないとモデルの評価を間違うこともある
        - 探索回数増やして分散を抑えるように手順を構築

    - 手順
        -   各データセットで、バリデーションセットで最適なハイパラの組み合わせを、~400回ほど反復してランダムサーチし、テストセットのスコアを算出

    - 上記手順を15回繰り返し、ランダムサーチの反復数$n$ごとの（バリデーションセットでのベストモデルの）テストスコアのスコアのプロット
        - 反復ごとにランダムサーチの順序はシャッフル
        - この手順で、各ランダムサーチの反復後の、バリデーションセットでの最良モデルの、テストセットでのスコアの期待値をブートストラップ的に推定することができる

- データの前処理
    - Gaussiznized features
        - scikit-learnの`QuantileTransofrmer`で特徴量をガウス化

    - Transformed regression targets
        - scikit-learnの`TransformedTargetRegressor`を使用
        - 回帰の設定では、分布がヘビーテイルである場合、ターゲット変数を対数変換
        - モデルの評価のために変換し直すオプションをハイパラに追加

    - OneHotEncoder
        - カテゴリ変数をネイティブに扱えないモデルに対しては、scikit-learnの`OneHotEncoder`を用いた

- 比較したモデル
    - Tree based models
        - RandomForest
        - GradientBoostingTrees (or HistGradientBoostingTrees)
        - XGBoost

    - Deep models
        - MLP
        - Resnet
        - FT_Transformer
        - SAINT



## 主張の有効性の検証方法
- 比較結果

    - <img src="picture/why do tree_Figure1 and 2.png" alt="why do tree_Figure1 and 2" style="zoom:80%;" />
        - Deep modelsは
            - 論文で主張されるようなSOTAではない
            - ハイパラチューニングに時間がかかる
            - カテゴリカル特徴が入るとTree-basedなモデルと差が広がる

- 結論

    - 中規模なデータセットでは、Tree-basedなモデルでよくない？

    

- **問:Tree-based modelsが持つどのような特徴・帰納的バイアスが表形式データに適しているのか？**

    - 発見:
        1.  表形式データで精度だすには”不規則な関数”が重要
            - データに平滑化カーネルかける（すなわち、”なめらか”にする）とTree-based modelでは精度がガクっと下がるがDeep modelsはそれほど変化しない
            - Deep modelsは不規則な関数にフィットするのに苦労する

        2.  Uninformativeな特徴がMLPのようなDeep modelsにより影響を与える
            -   表形式データには、有益でない特徴が多く含まれる
                -   Tree-based modelsは特徴を半分程度削っても精度に影響ない（図4参照）
                -   特徴の大部分に情報が少ない

            -   MLPのようなアーキテクチャは非情報的な特徴に対してロバストでない
                -   情報量の少ない特徴量を削除するとMLP（Resnet）と他のモデル（FT_TransformerとTree-based model）の差が縮まる
                -   MLP系のモデルは情報の少ない特徴に対してよわよわｗ

        3.  データは回転によらず不変であるため，学習手順も不変でなければならない（？）
            -   MLPはNg[2004]の意味で回転不変であること
                -   MLPをトレーing集合で学習し、テスト集合で評価する学習手順は、トレーニング集合とテスト集合の両方の特徴に回転（ユニタリー行列）を適用しても変化しない
                -   回転不変な学習手法は、（最悪の場合）無関係な特徴の個数に対して少なくとも線形に増加するサンプル複雑度をもつ
                    -   直感的な解釈:情報量の少ない特徴量を除去するために、回転不変なアルゴリズムはまず特徴量の元のほうこうを見つけ、次に情報量の少ないものを選択しなければならない

            -   回転不変性は表形式データには望ましくないことが多い
            -   **MLP系モデルには、視覚と同様に、回転不変なバイアスをコード化する自然な基底をもっている。この”自然な基底”では、非常に異なる統計的性質を持つ特徴を潜在的に混合してしまう回転をリカバーできない。**

- 50000サンプルの場合

    - 比較結果
        - 数値特徴のみの場合
            - <img src="picture/why do tree_Figure 9 and 10.png" alt="why do tree_Figure 9 and 10" style="zoom:80%;" />

        - 数値特徴＋カテゴリカル特徴の場合
            - <img src="picture/why do tree_Figure 11 and 12.png" alt="why do tree_Figure 11 and 12" style="zoom:80%;" />

        - 分類タスクだとFT_Transformerが上位にくる
        - 回帰タスクだとTree-based modelが強め
            - **[注意]**:50000サンプル以上あるデータセットがそもそも少ない。Deep modelsとTree-based modelsの違いを見るには不十分だと思うと著者は言っている。

- 残る問い

    - 表形式データに対するツリーベースモデルのパフォーマンスを説明する他の帰納的バイアスは何か？
    - 非常に小さなデータセットでは我々の評価はどう変わるのか？
    - 非常に大きなデータセットではどうだろうか？
    - NNやツリーベースのモデルにおいて、欠損データや高基数カテゴリ特徴のような特定の課題を扱うのに最適な方法は何か？
    - これらの最良の方法によって、欠損データを含む評価はどのように変化するのだろうか？


## 批評
- 表形式のデータセットの”均質化”やりすぎじゃない？
    - モデルドリブンな選び方というか
        - tree ベースのモデルの方が有利なデータセットの選び方じゃないか？
        - 億単位のサンプル数があったらNNベースな手法が精度高いんじゃないか？
            - 「そんだけデータないと勝てないなら、もっとデータ自体を限定的にしてデータにマッチした前提をもつモデルを適用したほうがリーズナブル（＝高精度かつ計算量が少ない）で実務的に使いやすいやん」ってツッコミには同意
    - 解かれたら価値のあるサンプル数の多いデータセットのほうがうれしくない？
        - 結局解けないデータセットですは駄目だけど…
- 前処理も画一的じゃない？
    - 表形式データに対する初手どうする？→前処理固定してtree ベースのモデルでOK。データセットごとモデルごとの掘り下げは自分でやりましょう。という示唆になってる
        - 実務的には大きな手間暇かけて微妙な性能向上を追うよりは、まぁまぁの高性能を少な時間でだすほうがベターか

- ”表形式データ


## 次に読むべき論文
- [Yury Gorishniy, Ivan Rubachev, Valentin Khrulkov, and Artem Babenko. Revisiting Deep Learning Models for Tabular Data. arXiv:2106.11959 [cs], June 2021.](https://arxiv.org/pdf/2106.11959.pdf)
    - FT-Transformerを提案してる
        - why do tree~の論文では、表形式データに対するDeep learningモデルの「ベストケース」としてとりあげられている
        - 中規模の表形式データセットでは精度でてないけどね（why do tree~の図1参照）
- [Andrew Y. Ng. Feature selection, L 1 vs. L 2 regularization, and rotational invariance. In Twenty-First International Conference on Machine Learning ICML ’04, page 78, Banff, Alberta, Canada, 2004. ACM Press. doi: 10.1145/1015330.1015435.](https://icml.cc/Conferences/2004/proceedings/papers/354.pdf)
    - MLPの回転不変性についてのAndrew Ng の論文
    - 読みたい
