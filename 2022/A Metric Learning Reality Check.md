# A Metric Learning Reality Check

## 論文について (掲載ジャーナルなど)
- [Musgrave, K., Belongie, S., & Lim, S. N. (2020, August). A metric learning reality check. In *European Conference on Computer Vision* (pp. 681-699). Springer, Cham.](https://arxiv.org/pdf/2003.08505.pdf)

## 概要
- 過去4年間に発表された**深層距離学習の各手法を再評価し、論文で報じられているほどのパフォーマンスの改善がなされていないこと**を実験的に示した論文

## 問題設定と解決したこと
- 距離学習は、「類似のデータは近くに、非類似のデータは遠くにあるような埋め込み空間にデータをマッピングするもの」である
    - 一般に、埋め込み損失と分類損失によって↑を達成する
        - 埋め込み損失：バッチ内のサンプル間の関係性に作用
        - 分類損失：埋め込み空間をクラスロジットのベクトルに変換する重み行列を含む

- 埋め込みがつかわれるケース
    - 情報検索（画像検索）
        - 顔認証、人物再認証

    - 分類損失を適用するのが難しい場合
        - 各サンプルにクラスラベルを割りあてることが困難であったり、コストがかかったり

- 埋め込み損失の他の応用例
    - 自己教師あり学習
        - 学習中に擬似ラベルをデータに適用するものとか
        - 疑似ラベルは、特定のバッチのデータ間の類似性を示すために存在し、埋め込み損失が用いられうる

    - 3次元点群特徴の学習
    - 可視化のための次元削減
    - 模倣学習
    - シーケンス予測
    - バニラ画像の分類

- 本論文では、近年発展してきた深層距離学習の最近の進歩と関連研究についてレビューする

- 距離学習で用いられるロス
    - 埋め込みロス

        - ペアロス
        - 古典的なペアベースの手法はcontrastive loss
            - 正のペア間の距離をある閾値よりも小さくし、負のペア間の距離をある閾値よりも大きくする
        - トリプレットロス
            - ペアベースのロスの理論的な欠点
            - ペア間の類似性と非類似性に大きなバラつきがあるにもかかわらず、すべてのペアに同じ距離閾値が適用される点
            - 上記の問題を理論的に解決するのが triplet margin loss
                - Tripletはアンカー、正、負のサンプルで構成
                - アンカーは負よりも正のサンプルに類似している
                - Triplet margin loss
                - 「アンカーと正のサンプルの距離」を「アンカーと負のサンプルの距離」より、あらかじめ定義されたマージンだけ小さくする
                - クラス間の非類似度の分散を考慮したモデルが可能になる
    - 分類ロス
        - 各列が特定のクラスに対応する重み行列をベースとした損失
        - （多くの手法で、）学習は重み行列と埋め込みベクトルを乗算してlogitsを求め、logitsに対して損失関数を適用する
            - 何がうれしいのかというと、**「通常のクラス分類問題をモデルに学習させることで、距離学習が実現できる」**こと

- 距離学習を適用する上での工夫
    - ペアロス・トリプレットロスのマイニング
        - 学習するのに最適なペアやトリプレットを見つける作業
        - 大きく分けてオフラインとオンラインのアプローチ
    - 学習プロセスに生成ネットワークを組み込む方法などなど
        - 細かい改善手法な感ある

## 何をどう使ったのか
- 本稿のContribution
    - 過去の文献の欠点の検証
        - 既存の手法と提案手法の不公平な比較の問題の指摘
        - 一般的に使用される精度指標の弱点の指摘
        - テストセットでのパラメータチューニングの指摘

    - 上記欠点に対処するための学習・評価プロトコルの提案
        - 提案したプロトコルで実験した結果、**ほとんどの手法が同じような性能を示すこと**がわかった

- 既存研究の欠点への指摘
    - 不公平な比較への指摘
        - ネットワークアーキテクチャが統一されていない問題
            - ネットワークアーキテクチャにGoogleNetつかったりResNet50使ったり
            - 提案手法による性能の向上を議論するなら、同じアーキテクチャ使って比較しろ！

        - データオーグメンテーションが統一されていない問題
            - 学習データばらつくやんけ！

        - 最適化手法や学習率の選択が統一されていない問題
            - テストセットの精度にどんだけ影響しとるんや！

        - ソースコードでやってることが論文に記載されていない問題
            - BNのパラメータを凍結すると、オーバーフィッティング対策になる工夫が論文中で触れられていないやつがあったぞ！

        - 結果の信頼区間を提示していない問題
            - 精度向上が一桁台前半であることが多い！
            - 複数回実行結果の平均と信頼区間が載せられてたらもっと意味のある内容になるやろ！

    - 一般に使われる指標の弱点の指摘
        - よく使われる精度指標
            - Recall@K
            - 正規化相互情報量（NMI）
            - F1スコア

        - これらは最適な指標ではないのでは？
        - トイデータでの確認
            - 埋め込み空間での様子が異なっても、上記3つの精度指標の値はほぼ100%になる
                - <img src="picture/A Metric Learning Reality Check Figure 1.png" alt="A Metric Learning Reality Check Figure 1" style="zoom:80%;" />
                - 一番右のような別れ方が理想的
                    - NMIとF1はどのケースでも100%となる
                    - 埋め込み空間でk-meansクラスタリングするときに、左とか真ん中のようにわかれると精度悪くなる場合があるやん

    - テストセットを用いた学習の調整への指摘

        - 多くの論文で、学習中に一定時間ごとにモデルのテストセット精度をチェックし、最も良いテストセット精度を報告してる
            - テストセットでパラメータチューニングしてるのと同じやんけ！

- ”正しい”評価方法の提案
    - 距離学習のロス関数以外の手法選択・パラメータをすべて統一して評価
    - ソースコード：[github.com/KevinMusgrave/powerful-benchmarker](https://github.com/KevinMusgrave/powerful-benchmarker)
- ”正しい”精度指標の提案
    - Mean Average Precision at R (MAP@R)
        - Mean Average PrecisionとR-precisionのアイデアの組み合わせ
        - 各サンプルの最近帽の数をRに設定したMean Average Precision
            - $\text{MAP@R}=\frac{1}{R}\sum^R_{i=1}P(i)$
            - $P(i)= \text{precision at }i \text{, if the ith retrieval is correct} \text{ or }0 \text{ otherwise}$

    - 


## 主張の有効性の検証方法
- 

## 批評
- こういう追試したらおかしいことがわかったでって論文好き
- 目的関数以外の実験条件を統一しての比較だけど、目的関数が変わったらベターな最適化手法も変化するのでは？
    - 手法の組み合わせによってはパフォーマンスが改善されるかも？
- テストセットでチューニングした結果報告はギルティだが
- 式（１）とか（２）で使ってる記号定義してや！$[]_+$ってやんやねん
    - 正にするって意味だろうけど

- logitsの定義（参考：[「logits」の意味について](https://stealthinu.hatenadiary.jp/entry/2019/06/17/151602)）
    - 「これから確率に変換しようとしている出力層のニューロンの出力値」のこと
    - すなわちくだけた表現だと、「シグモイド関数にかける前の分類モデルが出力した生の予測ベクトル」のこと


## 次に読むべき論文
- 
