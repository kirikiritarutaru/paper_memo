# Why do tree-based models still outperform deep learning on tabular data?

## 論文について (掲載ジャーナルなど)
- https://arxiv.org/pdf/2207.08815.pdf

## 概要
- ディープラーニングはテキストと画像のデータセットで大きな進歩が見られたが、表形式のデータでは優位性は明らかでない
- 本論文ではディープラーニング手法とXGBoostやランダムフォレストなど木ベースのモデルのベンチマークを提供
- 実験する中で、表形式に特化したニューラルネットワークを構築するための指針となる課題を導き出した。

## 問題設定と解決したこと
- 深層学習手法は本当に性能向上しているのか？調べてみました
    - 45の表形式のデータセットで検証
    - ベンチマーク方法も定義

- 結果:
    - Treeベースモデルのほうが処理速度も精度もいいぞ！
    - 表形式のデータに特化したNNの構築の指針を提案するぞ
        1.  有益でない特徴に頑健なモデルであること
        2.  データのorientationを保持するモデルであること
        3.  不規則な関数を容易に学習できるモデルであること


## 何をどう使ったのか
- 表形式データの”均質化”
    - 45個の表形式データセットを以下の基準で選択
        1.  異種カラムであること
            -   列は異なる性質の特徴に対応すること
        2.  高次元でないこと
        3.  文書化されていないデータセットであること（？）
            -   情報が少なすぎるデータセットは除外
        4.  I.I.D なデータセットであること
        5.  実世界のデータセットであること
        6.  小さすぎないこと
            -   特徴数＜4、サンプル数＜3000のデータセットは除外
        7.  簡単すぎないこと
            -   ロジスティック回帰でほぼわけられるような簡単なデータセットは除外
        8.  決定論的でないこと
            1.  チェスとかポーカーのようなゲームのデータセットを除外
        9.  中規模なデータセットであること
            -   10000サンプル程度（50000サンプルの大規模データセットについては別途検討）
        10.  欠損データがないこと
        11.  クラスのバランスがとれていること
             -   対象が複数のクラスである場合、最も多い2つのクラスを取ることによって2値化し、各クラスにサンプルの半分をふる
        12.  低カーディナリティカテゴリ特徴
             -   20項目異常のカテゴリ特徴を除外
        13.  高カーディナリティ数値特徴
             -   10個以下の一意な値をもつ数値特徴を除外


## 主張の有効性の検証方法
- 

## 批評
- 表形式のデータセットの”均質化”やりすぎじゃない？
    - モデルドリブンな選び方というか
    - 解かれたら価値のあるサンプル数の多いデータセットのほうがうれしくない？
        - 結局解けないデータセットですは駄目だけど…


## 次に読むべき論文
- 
